{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sistema de Recomendação Netflix - DSA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas necessárias\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import sklearn \n",
    "from scipy import sparse \n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatação dos gráficos\n",
    "\n",
    "matplotlib.use('nbAgg')\n",
    "plt.rcParams.update({'figure.max_open_warning':0})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#Marca o inicio da execução de leitura dos arquivos\n",
    "\n",
    "star = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um arquivo final chamado dados_netflix.csv\n",
    "\n",
    "#Se o arquivo não existir, cria-se o arquivo em modo de escrita(w)\n",
    "\n",
    "if not os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix.csv'):\n",
    "    #cria e abre o arquivo para gravação\n",
    "    dataset = open('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix.csv',mode = 'w')\n",
    "    #Lista para as linhas de arquivo \n",
    "    linhas = list()\n",
    "    #nomes e caminhos dos arquivos\n",
    "    arquivos = ['C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/combined_data_1.txt',\n",
    "                'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/combined_data_2.txt',\n",
    "                'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/combined_data_3.txt',\n",
    "                'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/combined_data_4.txt']\n",
    "    #loop por cada arquivo na lista de arquivos\n",
    "    for arquivo in arquivos:\n",
    "        print(\"Lendo arquivo{}...\".format(arquivo))\n",
    "        #com o arquivo aberto extraimos as linhas\n",
    "        with open(arquivo) as f:\n",
    "            for linha in f:\n",
    "                del linhas[:]\n",
    "                #divide a linha do arquivo pelo caracter de final de linha\n",
    "                linha = linha.strip()\n",
    "                #se encontrarmos \":\" fazemos o replace removendo o caracter, pois queremos apenas o ID do filme\n",
    "                if linha.endswith(':'):\n",
    "                    movie_id = linha.replace(':','')\n",
    "                #se não, criamos um list comprehension para separar as colunas por virgula\n",
    "                else:\n",
    "                    linhas = [x for x in linha.split(',')]\n",
    "                    linhas.insert(0, movie_id)\n",
    "                    dataset.write(','.join(linhas))\n",
    "                    dataset.write('\\n')\n",
    "        print('Concluído.\\n')\n",
    "    dataset.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprime o tempo de processamento\n",
    "print('Tempo total de processamento: ', datetime.now()-star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando o Dataframe\n",
    "\n",
    "df_netflix = pd.read_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix.csv',sep=',', names = ['movie','user','rating','date'])\n",
    "df_netflix.date = pd.to_datetime(df_netflix.date)\n",
    "print('Conluído!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenando o DF por data\n",
    "df_netflix.sort_values(by='date', inplace = True)\n",
    "print(\"Concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape dos dados\n",
    "df_netflix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando os primeiros dados\n",
    "\n",
    "df_netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ANÁLISE EXPLORATÓRIA DE DADOS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumo dos dados\n",
    "\n",
    "print(\"Resumo dos Dados\")\n",
    "print('-'*50)\n",
    "print('Número total de filmes: ', len(np.unique(df_netflix.movie)))\n",
    "print('Número total de usuários: ', len(np.unique(df_netflix.user)))\n",
    "print('Número total de avaliações: ', df_netflix.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = len(np.unique(df_netflix.user))\n",
    "total_movies = len(np.unique(df_netflix.movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando as estatisticas da coluna de avaliação (Rating)\n",
    "df_netflix.describe()['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando valores ausentes\n",
    "sum(df_netflix.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando se há valores duplicados (não consideramos a data)\n",
    "sum(df_netflix.duplicated(['movie','user','rating']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir com a EDA, faremos o split dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criaremos um dataset em disco com os dados de treino, para que não haja necessidade de executar todo\n",
    "#o processo de carga novamente a cada vez que executar o notebook\n",
    "\n",
    "if not os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix_treino.csv'):\n",
    "    df_netflix.iloc[:int(df_netflix.shape[0]*0.80)].to_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix_treino.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criaremos um dataset em disco com os dados de teste, para que não haja necessidade de executar todo\n",
    "#o processo de carga novamente a cada vez que executar o notebook\n",
    "\n",
    "if not os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix_teste.csv'):\n",
    "    df_netflix.iloc[int(df_netflix.shape[0]*0.80):].to_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix_teste.csv', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para liberar memoria, deletaremos o dataset original\n",
    "del df_netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando os dados de treino e teste em dataframe do pandas\n",
    "df_netflix_treino = pd.read_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix_treino.csv', parse_dates = ['date'])\n",
    "df_netflix_teste = pd.read_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_netflix_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumo dos dados de treino\n",
    "\n",
    "print(\"Resumo dos Dados Treino\")\n",
    "print('-'*50)\n",
    "print('Número total de filmes: ', len(np.unique(df_netflix_treino.movie)))\n",
    "print('Número total de usuários: ', len(np.unique(df_netflix_treino.user)))\n",
    "print('Número total de avaliações: ', df_netflix_treino.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para ajustar as unidades de medida\n",
    "\n",
    "def ajusta_unidades(num, units = 'M'):\n",
    "    units = units.lower()\n",
    "    num = float(num)\n",
    "    if units == 'k':\n",
    "        return str(num/10**3)+\"K\"\n",
    "    if  units == 'm':\n",
    "        return str(num/10**6)+\"M\"\n",
    "    if  units == 'b':\n",
    "        return str(num/10**9)+\"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supressão de warnings\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a distribuição dos dados de 'Rating'\n",
    "fig, ax = plt.subplots()\n",
    "sns.countplot(df_netflix_treino.rating)\n",
    "plt.title('Distribuição das Avaliações nos Dados de Treino', fontsize = 15)\n",
    "ax.set_yticklabels([ajusta_unidades(item, 'M') for item in ax.get_yticks()])\n",
    "ax.set_ylabel('Número de Avaliações (em Milhões)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar se o dia da semana tem influência na avaliação do usuário.\n",
    "Para isso precisaremos incluir uma nova coluna com o dia da semana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrai o dia da semana e grava em nova coluna\n",
    "df_netflix_treino['dia_semana'] = df_netflix_treino['date'].dt.strftime('%A')\n",
    "df_netflix_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "fig, ax = plt.subplots()\n",
    "sns.countplot(x = 'dia_semana', data = df_netflix_treino, ax = ax)\n",
    "plt.title('Número de Avaliações por Dia da Semana', fontsize = 15)\n",
    "plt.ylabel('Total de Avaliações')\n",
    "plt.xlabel('')\n",
    "ax.set_yticklabels([ajusta_unidades(item,'M') for item in ax.get_yticks()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Média das avaliações por dia da semana\n",
    "media_dia_semana = df_netflix_treino.groupby(by = ['dia_semana'])['rating'].mean()\n",
    "print('Média de avaliações')\n",
    "print('-'*30)\n",
    "print(media_dia_semana)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o dia da semana parece não ter influencia na avaliação dos usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análise das avaliações ao longo do tempo\n",
    "fig = plt.figure(figsize=plt.figaspect(.45))\n",
    "ax = df_netflix_treino.resample('m',on = 'date')['rating'].count().plot()\n",
    "ax.set_title('Número de Avaliações por mês')\n",
    "plt.xlabel('Mês')\n",
    "plt.ylabel('Número de Avaliações por Mês')\n",
    "ax.set_yticklabels([ajusta_unidades(item,'M') for item in ax.get_yticks()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usuários que mais avaliaram\n",
    "num_aval_user = df_netflix_treino.groupby(by='user')['rating'].count().sort_values(ascending=False)\n",
    "num_aval_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumo estatístico\n",
    "num_aval_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de densidade de probabilidade  \n",
    "fig =  plt.figure(figsize= plt.figaspect(.45))\n",
    "ax1 = plt.subplot(121)\n",
    "sns.kdeplot(num_aval_user, shade = True, ax=ax1)\n",
    "plt.xlabel('Número de Avaliações por Usuários')\n",
    "plt.title('PDF - Função Densidade de Probabilidade')\n",
    "ax2 = plt.subplot(122)\n",
    "sns.kdeplot(num_aval_user, shade = True, cumulative = True, ax = ax2)\n",
    "plt.xlabel('Número de Avaliações por Usuário')\n",
    "plt.title('CDF - Função de Densidade Acumulada')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraindo os percentis\n",
    "percentis = num_aval_user.quantile(np.arange(0,1.01,0.01), interpolation='higher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentis[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "fig = plt.figure(figsize= plt.figaspect(.45))\n",
    "plt.title(\"Percentis\")\n",
    "percentis.plot()\n",
    "\n",
    "#Quartis com diferença de 0.05\n",
    "plt.scatter(x = percentis.index[::5],\n",
    "            y = percentis.values[::5],\n",
    "            c = 'orange',\n",
    "            label = 'Percentis com intervalo de 0.05')\n",
    "\n",
    "#Quartis com diferença de 0.25\n",
    "plt.scatter(x = percentis.index[::25],\n",
    "            y = percentis.values[::25],\n",
    "            c = 'm',\n",
    "            label = 'Percentis com intervalo de 0.25')\n",
    "\n",
    "#Label e legenda\n",
    "plt.ylabel('Número de Avaliações por Usuário')\n",
    "plt.xlabel('Valor de Percentis')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "#Marca os percentis 25, 50, 75 e 100\n",
    "for x, y in zip(percentis.index[::25],percentis[::25]):\n",
    "    plt.annotate(s = '({} , {})'.format(x,y) , xy = (x, y), xytext = (x - 0.05, y+500), fontweigth = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de Matriz Esparsa Treino\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria a matriz em formato de numpy caso não exista\n",
    "#Se existe apenas carregamos\n",
    "if os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_treino.npz'):\n",
    "    matriz_esparsa_treino = sparse.load_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_treino.npz')\n",
    "    print('Matriz Carregada!')\n",
    "else:\n",
    "    matriz_esparsa_treino = sparse.csr_matrix((df_netflix_treino.rating.values, (df_netflix_treino.user.values,\n",
    "                                                                                 df_netflix_treino.movie.values)),)\n",
    "print('Matriz Criada, o shape é: (user, movie):', matriz_esparsa_treino.shape)\n",
    "sparse.save_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_treino.npz', matriz_esparsa_treino)\n",
    "print('Matriz salva em disco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a esparsidade da matriz\n",
    "linhas, colunas = matriz_esparsa_treino.shape\n",
    "elementos_nonzero = matriz_esparsa_treino.count_nonzero()\n",
    "print(\"Esparsidade da matriz de treino: {} %\".format(( 1 - (elementos_nonzero/ (linhas * colunas))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a matriz esparsa de teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria a matriz em formato de numpy caso não exista\n",
    "#Se existe apenas carregamos\n",
    "if os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_teste.npz'):\n",
    "    matriz_esparsa_teste = sparse.load_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_teste.npz')\n",
    "    print('Matriz Carregada!')\n",
    "else:\n",
    "    matriz_esparsa_teste = sparse.csr_matrix((df_netflix_teste.rating.values, (df_netflix_teste.user.values,\n",
    "                                                                                 df_netflix_teste.movie.values)),)\n",
    "print('Matriz Criada, o shape é: (user, movie):', matriz_esparsa_teste.shape)\n",
    "sparse.save_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_teste.npz', matriz_esparsa_teste)\n",
    "print('Matriz salva em disco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a esparsidade da matriz\n",
    "linhas, colunas = matriz_esparsa_teste.shape\n",
    "elementos_nonzero = matriz_esparsa_teste.count_nonzero()\n",
    "print(\"Esparsidade da matriz de teste: {} %\".format(( 1 - (elementos_nonzero/ (linhas * colunas))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a média global de todas as avaliações de filme, avaliação por usuário, avaliação média por filme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Média global de todas as avaliações de usuários\n",
    "medias = dict()\n",
    "media_global = matriz_esparsa_treino.sum() / matriz_esparsa_treino.count_nonzero()\n",
    "medias['global'] = media_global\n",
    "medias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construção da função para cálculo da média de avaliações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de cálculo da média\n",
    "def calc_media_aval(sparse_matrix, of_users):\n",
    "    #1 eixo do usuario\n",
    "    #0 eixo do filme\n",
    "    ax = 1 if of_users else 0\n",
    "    \n",
    "    #soma\n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    \n",
    "    #Matriz boolena de avaliações\n",
    "    is_rated = sparse_matrix !=0\n",
    "    \n",
    "    #Numero de avaliações de cada usuário ou filme\n",
    "    no_of_ratings = is_rated.sum(axis=ax).A1\n",
    "    \n",
    "    #Ids maximos de usuarios e filmes na matriz esparsa\n",
    "    u, m = sparse_matrix.shape\n",
    "    \n",
    "    #dicionario de usuarios e suas avaliaçoes medias\n",
    "    media_aval = {i: sum_of_ratings[i]/no_of_ratings[i] for i in range(u if of_users else m) if no_of_ratings[i] !=0}\n",
    "    \n",
    "    #Retorna o dict media_aval\n",
    "    return media_aval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medias de avaliação por usuário\n",
    "medias['user'] = calc_media_aval(matriz_esparsa_treino, of_users=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medias de avaliação por filme\n",
    "medias['movie'] = calc_media_aval(matriz_esparsa_treino, of_users=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos verificar um usuário qualquer\n",
    "medias['user'][149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos verificar um filme qualquer\n",
    "medias['movie'][32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDFs e CDs da média. Avaliações de usuários e filmes (dados treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize= plt.figaspect(.45))\n",
    "fig.suptitle('Média de avaliações por usuários e por filme:', fontsize=15)\n",
    "\n",
    "ax1.set_title('Média de Avaliações de Usuários')\n",
    "\n",
    "#Obternis a lista de avaliações médias do usuário no dicionário de médias\n",
    "medias_usuarios = [rat for rat in medias['user'].values()]\n",
    "sns.distplot(medias_usuarios, ax= ax1, hist = False, kde_kws=dict(cumulative = True), label='CDF')\n",
    "sns.distplot(medias_usuarios, ax= ax1, hist = False, label='PDF')\n",
    "\n",
    "#obtemos a lista de avaliações médias de filme no dicionário\n",
    "medias_filme = [rat for rat in medias['movie'].values()]\n",
    "sns.distplot(medias_usuarios, ax= ax2, hist = False, kde_kws=dict(cumulative = True), label='CDF')\n",
    "sns.distplot(medias_usuarios, ax= ax2, hist = False, label='PDF')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PROBLEMA DO COLD START*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cold start de usuários\n",
    "usuarios_treino = len(medias['user'])\n",
    "novos_usuarios = total_users - usuarios_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print \n",
    "print('Total Geral de Usuários:', total_users)\n",
    "print('Total Geral de Usuários em Treino:', usuarios_treino)\n",
    "print('Total Geral de Usuários que NÃO estão em treino: {} ({}%)'.format(novos_usuarios,\n",
    "                                                                         np.round((novos_usuarios / total_users)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75148 usuários nao fazem parte dos dados de treino, ou seja, não temos como aprender o padrão de avaliação desses usuário. esse é o problema do cold start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cold start de usuários\n",
    "filmes_treino = len(medias['movie'])\n",
    "novos_filmes = total_movies - filmes_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print \n",
    "print('Total Geral de Filmes:', total_movies)\n",
    "print('Total Geral de Filmes em Treino:', filmes_treino)\n",
    "print('Total Geral de Filmes que NÃO estão em treino: {} ({}%)'.format(novos_filmes,\n",
    "                                                                         np.round((novos_filmes / total_movies)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "346 filmes não aparecem nos dados de treino. Teremos que lidar com isso quando trabalharmos no modelo de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CALCULANDO A MATRIZ DE SIMLIARIDADE DE USUÁRIOS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de calculo de similaridade\n",
    "def calc_similaridade_user(sparse_matrix,\n",
    "                           compute_for_few = False,\n",
    "                           top = 100,\n",
    "                           verbose = False,\n",
    "                           verb_for_n_rows = 20,\n",
    "                           draw_time_taken = True):\n",
    "    #Variaveis de controle\n",
    "    no_of_users, _ = sparse_matrix.shape\n",
    "    row_ind, col_ind = sparse_matrix.nonzero()\n",
    "    row_ind = sorted(set(row_ind))\n",
    "    time_taken = []\n",
    "    rows, cols, data = [], [], []\n",
    "    if verbose: print(\"Calculando top\", top, \"similaridades para cada usuário...\")\n",
    "    start = datetime.now()\n",
    "    temp = 0\n",
    "    \n",
    "    #Loop pela matriz\n",
    "    for row in row_ind[:top] if compute_for_few else row_ind:\n",
    "        temp = temp +1\n",
    "        prev = datetime.now()\n",
    "        #Calculando similaridade de cosseno\n",
    "        sim = cosine_similarity(sparse_matrix.getrow(row), sparse_matrix).ravel()\n",
    "        top_sim_ind = sim.argsort()[-top:]\n",
    "        top_sim_val = sim[top_sim_ind]\n",
    "        rows.extend([row]*top)\n",
    "        cols.extend(top_sim_ind)\n",
    "        data.extend(top_sim_val)\n",
    "        time_taken.append(datetime.now().timestamp()-prev.timestamp())\n",
    "        \n",
    "        if verbose:\n",
    "            if temp%verb_for_n_rows == 0:\n",
    "                print(\"Cálculo concluído para {} usuários [ tempo total: {} ]\".format(temp, datetime.now()-start))\n",
    "                \n",
    "    if verbose: print('Criação de matriz esparsa a partir das semelhanças computadas...')\n",
    "    \n",
    "    if draw_time_taken:\n",
    "        plt.plot(time_taken, label = 'Tempo de cálculo de cada usuário')\n",
    "        plt.plot(np.cumsum(time_taken), label = 'Tempo Total')\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.xlabel('Usuário')\n",
    "        plt.ylabel('Tempo (segundos)')\n",
    "        plt.show()\n",
    "    return sparse.csr_matrix((data, (rows, cols)), shape = (no_of_users, no_of_users)), time_taken            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a similaridade\n",
    "#Marca o início\n",
    "start = datetime.now()\n",
    "\n",
    "#Calcula a similaridade\n",
    "matriz_esparsa_user, _ = calc_similaridade_user(matriz_esparsa_treino,\n",
    "                                                compute_for_few= True,\n",
    "                                                top = 100,\n",
    "                                                verbose = True)\n",
    "\n",
    "print(\"Tempo Total de Processamento:\", datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentaremos reduzir a dimensionalidade usando SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*REDUÇÃO DE DIMENSIONALIDADE COM TRUNCATEDSVD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redução de dimensionalidae\n",
    "#Marca o ínicio\n",
    "start = datetime.now()\n",
    "\n",
    "#Cria o objeto TrucatedSVD reduzindo a dimensionalidade para 500 dims.\n",
    "netflix_svd = TruncatedSVD(n_components= 500, algorithm='randomized', random_state= 15)\n",
    "\n",
    "#Aplica o TruncatedSVD\n",
    "trunc_svd = netflix_svd.fit_transform(matriz_esparsa_treino)\n",
    "\n",
    "print(\"Tempo total de processamento:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CALCULAR A VARIANCIA EXPLICADA PELOS COMPONENTES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a variancia explicada\n",
    "expl_var = np.cumsum(netflix_svd.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "fig, (ax1) = plt.subplots(nrows= 1, ncols = 1, figsize = plt.figaspect(.45))\n",
    "\n",
    "ax1.set_ylabel(\"Variância Explicada\", fontsize = 15)\n",
    "ax1.set_xlabel(\"Fatores Latentes\", fontsize = 15)\n",
    "ax1.plot(expl_var)\n",
    "\n",
    "#Marcar algumas combinações para ficar mais claro\n",
    "ind = [1, 2, 4, 8, 20, 60, 100, 200, 300, 400, 500]\n",
    "ax1.scatter(x = [i-1 for i in ind], y = expl_var[[i-1 for i in ind]],c = '#ee4422')\n",
    "\n",
    "for i in ind:\n",
    "    ax1.annotate(s = \"({}, {}\".format(i, np.round(expl_var[i-1], 2)), xy = (i-1, expl_var[i-1]),\n",
    "                 xytext = (i+20, expl_var[i-1] - 0.01), fontweight = 'bold')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projetando a matriz no espaço de 500 dims.\n",
    "trunc_matrix = matriz_esparsa_treino.dot(netflix_svd.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape\n",
    "trunc_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIpo\n",
    "type.(trunc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando em disco a matriz com a dimensionalidade reduzida pra 500\n",
    "if not os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_user_truncada.npz'):\n",
    "    matriz_esparsa_user_truncada = sparse.csr_matrix(trunc_matrix)\n",
    "    sparse.save_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_user_truncada.npz', matriz_esparsa_user_truncada)\n",
    "else:\n",
    "    matriz_esparsa_user_truncada = sparse.load_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_user_truncada.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "matriz_esparsa_user_truncada.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calcular a similaridade com a matriz truncada*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a similaridade de usuários\n",
    "trunc_sim_matrix, _ = calc_similaridade_user(matriz_esparsa_user_truncada,\n",
    "                                             compute_for_few=True,\n",
    "                                             top = 50,\n",
    "                                             verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CALCULANDO A MATRIZ DE SIMILARIDADE PARA FILMES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria se não existir\n",
    "if not os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_filme.npz'):\n",
    "    matriz_esparsa_filme = cosine_similarity(x = matriz_esparsa_treino.T, dense_output = False)\n",
    "    sparse.save_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_filme.npz')\n",
    "else:\n",
    "    matriz_esparsa_filme = sparse.load_npz('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_filme.npz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "matriz_esparsa_filme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrai os ids dos filmes\n",
    "movie_ids = np.unique(matriz_esparsa_filme.nonzero()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a similaridade de filmes de acordo com o padrão de avaliação do usuário\n",
    "filmes_similares = {}\n",
    "\n",
    "#loop pelos ids dos filmes\n",
    "for movie in movie_ids:\n",
    "    #obtemos os top filmes semelhantes e armazenamos no dicionário\n",
    "    filmes_sim = matriz_esparsa_filme[movie].toarray().ravel().argsort()[::-1][1:]\n",
    "    filmes_similares[movie] = filmes_sim[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filmes similares ao filme de id 43\n",
    "filmes_similares[43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ENCONTRAR OS FILMES SEMELHANTES USANDO A MATRIZ DE SIMILARIDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos carregar os títulos dos filmes do arquivo csv fornecido pela Netflix\n",
    "titulos_filmes = pd.read_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/movies_titles.csv',\n",
    "                             sep = ',',\n",
    "                             header = None,\n",
    "                             names = ['ID_Filme', 'Ano_Lancamento','Titulo'],\n",
    "                             verbose = True,\n",
    "                             index_col = 'ID_Filme',\n",
    "                             encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiza dados\n",
    "titulos_filmes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Filmes similares ao filme 43*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID do filme\n",
    "id_filme = 43\n",
    "print(\"Filme\", titulos_filmes.loc[id_filme].values[1])\n",
    "print(\"Total de avaliações de usuários = {}.\".format(matriz_esparsa_treino[:,id_filme].getnnz()))\n",
    "print(\"Encotramos {} filmes que são similares a este e vamos imprimir os mais similares\".format(matriz_esparsa_filme[:,id_filme].getnnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encontrando todas similaridads\n",
    "similarities = matriz_esparsa_filme[id_filme].toarray().ravel()\n",
    "similar_indices = similarities.argsort()[::-1][1:]\n",
    "similarities[similar_indices]\n",
    "sim_indices = similarities.argsort()[::-1][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize = plt.figaspect(.45))\n",
    "plt.plot(similarities[sim_indices], label = 'Todas as Avaliações')\n",
    "plt.plot(similarities[sim_indices[:100]], label = 'Top 100 Filmes Similares')\n",
    "plt.title(\"Filmes Similares ao Filme {}\".format(id_filme), fontsize=25)\n",
    "plt.xlabel(\"Filmes\", fontsize = 15)\n",
    "plt.ylabel(\"Similaridade de Cosseno\", fontsize = 15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 filmes similares ao filme 43\n",
    "titulos_filmes.loc[sim_indices[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Até aqui fizemos o nosso sistema de recomendação. Agora iniciaremos a construção de um modelo de ML a fim de prever a avaliação que o usuário atribuirá a um filme.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando os pacotes \n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import xgboost as xgb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir uma função para extrair amostras dos dados, já que, se trata de muitos dados e demoraria muito tempo para executar tudo de uma vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para extrair amostra da matriz esparsa\n",
    "from random import sample\n",
    "\n",
    "\n",
    "def gera_amostra(sparse_matrix, num_users, num_movies, path, verbose = True):\n",
    "    #Tupla: row, col e rating da matriz esparsa\n",
    "    row_ind, col_ind, ratings = sparse.find(sparse_matrix)\n",
    "    users = np.unique(row_ind)\n",
    "    movies = np.unique(col_ind)\n",
    "    \n",
    "    #random seed para reproduzir o processo aleatorio\n",
    "    np.random.seed(15)\n",
    "    \n",
    "    #Amostras de usuarios e filmes\n",
    "    sample_users = np.random.choice(users, num_users, replace = True)\n",
    "    sample_movies = np.random.choice(movies, num_movies, replace = True)\n",
    "    \n",
    "    #Gera mascara boolena\n",
    "    mask = np.logical_and(np.isin(row_ind, sample_users), np.isin(col_ind, sample_movies))\n",
    "    \n",
    "    #matriz esparsa com as amostras da matriz original\n",
    "    amostra_matriz_esparsa = sparse.csr_matrix((ratings[mask], (row_ind[mask], col_ind[mask])),\n",
    "                                               shape = (max(sample_users)+1, max(sample_movies)+1))\n",
    "    \n",
    "    #Salva em disco\n",
    "    sparse.save_npz(path, amostra_matriz_esparsa)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Tarfe concluída. \\n')\n",
    "        \n",
    "        \n",
    "    return amostra_matriz_esparsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gerando a amostra de treino*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando uma amostra\n",
    "\n",
    "#caminho onde esta a matriz original\n",
    "caminho_original_treino =  'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_treino.npz'\n",
    "\n",
    "#carregando a matriz\n",
    "matriz_loaded_treino = sparse.load_npz(caminho_original_treino)\n",
    "\n",
    "#onde salvar a amostra\n",
    "path = 'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/amostra_matriz_esparsa_treino.npz'\n",
    "\n",
    "#obtemos uma amostra de 10000 usuários e 1000 filmes\n",
    "amostra_treino = gera_amostra(matriz_loaded_treino, \n",
    "                              num_users=10000, \n",
    "                              num_movies=1000, \n",
    "                              path = path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando uma amostra\n",
    "\n",
    "#caminho onde está a matriz original\n",
    "caminho_original_teste =  'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/matriz_esparsa_teste.npz'\n",
    "\n",
    "#carregando a matriz\n",
    "matriz_loaded_teste = sparse.load_npz(caminho_original_teste)\n",
    "\n",
    "#onde salvar a amostra\n",
    "path = 'C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/amostra_matriz_esparsa_teste.npz'\n",
    "\n",
    "#obtemos uma amostra de 2000 usuários e 200 filmes\n",
    "amostra_teste = gera_amostra(matriz_loaded_teste, \n",
    "                              num_users=2000, \n",
    "                              num_movies=200, \n",
    "                              path = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resumo\n",
    "print('Numero de amostras na matriz de amostras de TREINO: {}'.format(amostra_treino.count_nonzero()))\n",
    "print('Numero de amostras na matriz de amostras de TESTE: {}'.format(amostra_teste.count_nonzero()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Métricas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria um dicionário\n",
    "amostra_medias_treino = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular a media de avaliações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import avg\n",
    "\n",
    "\n",
    "def calcula_media_ratings(sparse_matrix, of_users):\n",
    "    #media de avaliações\n",
    "    #1 eixo de users\n",
    "    #0 eixo de filmes\n",
    "    ax = 1 if of_users else 0\n",
    "    \n",
    "    #soma das avaliaçoes\n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    \n",
    "    #Matriz boolena de avaliações(se o usuario avaliou aquele filme ou nao)\n",
    "    is_rated = sparse_matrix != 0\n",
    "    \n",
    "    #num de avaliaçoes de cada usuario ou filme\n",
    "    no_of_ratings = is_rated.sum(axis = ax).A1\n",
    "    \n",
    "    #Ids da matriz esparsa, u de user m de movie\n",
    "    u, m = sparse_matrix.shape\n",
    "    \n",
    "    #dict de users e suas avaliaçoes\n",
    "    avg_ratings = {i:sum_of_ratings[i] / no_of_ratings[i]\n",
    "                   for i in range(u if of_users else m)\n",
    "                   if no_of_ratings[i] != 0}\n",
    "    \n",
    "    return avg_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media global das avaliaçoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media global\n",
    "mediaglobal = amostra_treino.sum() / amostra_treino.count_nonzero()\n",
    "amostra_treino['global'] = mediaglobal\n",
    "amostra_medias_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media por usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media de avaliaçao dos usuarios\n",
    "amostra_medias_treino['user'] = calcula_media_ratings(amostra_treino, of_users= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrair um dos usuarios do dict de filmes, o objetivo é so automatizar o processo\n",
    "um_usuario = [a for a, b in amostra_medias_treino['user'].items()][0]\n",
    "um_usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Media de Avaliação do Usuario ' + str(um_usuario) + ':', amostra_medias_treino['user'][um_usuario])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media por filme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media de avaliaçao dos usuarios\n",
    "amostra_medias_treino['movie'] = calcula_media_ratings(amostra_treino, of_users= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrair um dos usuarios do dict de filmes, o objetivo é so automatizar o processo\n",
    "um_filme = [a for a, b in amostra_medias_treino['movie'].items()][0]\n",
    "um_filme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Media de Avaliação do Filme ' + str(um_filme) + ':', amostra_medias_treino['movie'][um_filme])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Formatando os dados*\n",
    "\n",
    "-variaveis de entrada-\n",
    "GAvg -> media global das avals\n",
    "sur1, sur2... -> (avaliação de usuarios semelhantes)\n",
    "smr1, smr2... -> (filmes semelhantes avaliados por um usuario)\n",
    "UAvg -> media das avaliaçoes dos usuarios\n",
    "MAvg -> media das avaliaçoes do filme\n",
    "\n",
    "-Variavel Target-\n",
    "rating -> avaliação do filme dada pelo usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PREPARANDO OS DADOS DE TREINO PARA O MODELO DE REGRESSÃO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraindo os dados da matriz de amostras\n",
    "amostra_usuarios_treino, amostras_filmes_treino, amostra_avaliacoes_treino = sparse.find(amostra_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a celula abaixo demora muito para ser executada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando se o arquivo ja existe\n",
    "\n",
    "if os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_treino_reg.csv'):\n",
    "    print('O arquivo ja existe e nao precisa ser criado novamente')\n",
    "else:\n",
    "    print('Preparando {} tuplas para o dataset... \\n'.format(len(amostra_medias_treino)))\n",
    "    with open('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_treino_reg.csv', mode = 'w') as reg_data_file:\n",
    "        count = 0\n",
    "        for (user, movie, rating) in zip(amostra_usuarios_treino,amostras_filmes_treino, amostra_avaliacoes_treino):\n",
    "            #### avaliaçao de um filme por usuarios similares ao usuario corrente ####\n",
    "            #calcula usuario similar ao usuario corrente\n",
    "            user_sim = cosine_similarity(amostra_treino[user],amostra_treino).ravel()\n",
    "            \n",
    "            #obtem top user\n",
    "            top_sim_user = user_sim.argsort()[::-1][1:]\n",
    "            \n",
    "            #top ratings\n",
    "            top_ratings = amostra_treino[top_sim_user, movie].toarray().ravel()\n",
    "            \n",
    "            #top 5 usuarios similares\n",
    "            top_sim_user_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_user_ratings.extend([amostra_treino['movie'][movie]]*(5 - len(top_sim_user_ratings)))\n",
    "            \n",
    "            \n",
    "            #### avaliaçao por usuario para filmes similares ao filme corrente ####\n",
    "            #calcula filme similar ao filme corrente\n",
    "            movie_sim = cosine_similarity(amostra_treino[movie],amostra_treino).ravel()\n",
    "            \n",
    "            #obtem top movie\n",
    "            top_sim_movie = movie_sim.argsort()[::-1][1:]\n",
    "            \n",
    "            #top ratings\n",
    "            top_ratings = amostra_treino[top_sim_movie, movie].toarray().ravel()\n",
    "            \n",
    "            #top 5 usuarios similares\n",
    "            top_sim_movie_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_movie_ratings.extend([amostra_treino['movie'][movie]]*(5 - len(top_sim_movie_ratings)))\n",
    "            \n",
    "            #### prepara a linha que sera armazenada no arquivo ####\n",
    "            row = []\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            \n",
    "            #Adicionamos outros atributos\n",
    "            row.append(amostra_medias_treino['global'])\n",
    "            row.extend(top_sim_user_ratings)\n",
    "            row.extend(top_sim_movie_ratings)\n",
    "            row.append(amostra_medias_treino['user'][user])\n",
    "            row.append(amostra_medias_treino['movie'][movie])\n",
    "            \n",
    "            row.append(rating)\n",
    "            count = count + 1\n",
    "            \n",
    "            #if count == 10: \n",
    "                #break \n",
    "            \n",
    "            reg_data_file.write(','.join(map(str,row)))\n",
    "            reg_data_file.write('\\n')\n",
    "            if (count)%10000 == 0:\n",
    "                print(\"Concluido para {} linhas----- {}\".format(count, datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregamos o arquivo e colocamos em um DF\n",
    "from os import getloadavg\n",
    "\n",
    "\n",
    "df_dados_treino_reg = pd.read_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_treino_reg.csv',\n",
    "                                  names = ['user',\n",
    "                                  'movie',\n",
    "                                  'GAvg', \n",
    "                                  'sur1',\n",
    "                                  'sur2',\n",
    "                                  'sur3',\n",
    "                                  'sur4',\n",
    "                                  'sur5',\n",
    "                                  'smr1',\n",
    "                                  'smr2',\n",
    "                                  'smr3',\n",
    "                                  'smr4',\n",
    "                                  'smr5',\n",
    "                                  'UAvg',\n",
    "                                  'MAvg',\n",
    "                                  'rating'], header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados\n",
    "df_dados_treino_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PREPARANDO OS DADOS DE TESTE PARA O MODELO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraindo os dados da matriz de amostras\n",
    "amostra_usuarios_teste, amostras_filmes_teste, amostra_avaliacoes_teste = sparse.find(amostra_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_teste_reg.csv'):\n",
    "    print(\"O arquivo já existe e não precisa ser criando novamente\")\n",
    "else:\n",
    "    print(\"Preparando {} tuplas para o dataset..\\n\".format(len(amostra_teste)))\n",
    "    with open('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/dados_teste_reg.csv', mode = 'w') as reg_data_file:\n",
    "        count = 0\n",
    "        for (user, movie, rating) in zip(amostra_usuarios_teste, amostras_filmes_teste, amostra_avaliacoes_teste):\n",
    "            st = datetime.now()\n",
    "            \n",
    "            #similaridade de usuarios\n",
    "            try:\n",
    "                user_sim = cosine_similarity(amostra_treino[user], amostra_treino).ravel()\n",
    "                top_sim_user = user_sim.argsort()[::-1][1:]\n",
    "                top_ratings = amostra_treino[top_sim_user, movie].toarray().ravel()\n",
    "                top_sim_user_ratings = list(top_ratings[top_ratings !=0 ][:5])\n",
    "                top_sim_user_ratings.extend([amostra_medias_treino['movie'][movie]]*(5 - len(top_sim_user_ratings)))\n",
    "                \n",
    "            except (IndexError, KeyError):\n",
    "                top_sim_user_ratings.extend([amostra_medias_treino['global']]*(5 - len(top_sim_user_ratings)))\n",
    "            except:\n",
    "                print(user,movie)\n",
    "                raise\n",
    "            \n",
    "            #Similaridade dos filmes\n",
    "            try:\n",
    "                movie_sim = cosine_similarity(amostra_treino[:,movie].T,\n",
    "                                              amostra_treino.T).ravel()\n",
    "                top_sim_movie = movie_sim.argsort()[::-1][1:]\n",
    "                top_ratings = amostra_treino[user, top_sim_movie].toarray().ravel()\n",
    "                top_sim_movie_ratings = list(top_ratings[top_ratings !=0 ][:5])\n",
    "                top_sim_movie_ratings.extend([amostra_medias_treino['user'][user]]*(5 - len(top_sim_movie_ratings)))\n",
    "            except(IndexError, KeyError):\n",
    "                top_sim_movie_ratings.extend([amostra_medias_treino['global']]*(5 - len(top_sim_movie_ratings)))\n",
    "            except:\n",
    "                raise\n",
    "            \n",
    "            #prepara os dados para gravar o arquivo\n",
    "             # Prepara os dados para gravar no arquivo\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            row.append(amostra_medias_treino['global']) \n",
    "            row.extend(top_sim_user_ratings)\n",
    "            row.extend(top_sim_movie_ratings)\n",
    "            \n",
    "            try:\n",
    "                row.append(amostra_medias_treino['user'][user])\n",
    "            except KeyError:\n",
    "                row.append(amostra_medias_treino['global'])\n",
    "            except:\n",
    "                raise\n",
    "            \n",
    "            row.append(rating)\n",
    "            \n",
    "            count = count +1\n",
    "            \n",
    "            #if count == 5\n",
    "                #break\n",
    "            \n",
    "            reg_data_file.write(','.join(map(str,row)))\n",
    "            reg_data_file.write('\\n')\n",
    "            if(count)%1000 == 0\n",
    "            print('Concluido em {} linhas---- {}'.format(count, datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o dataset de teste\n",
    "df_dados_teste_reg = pd.read_csv('dados/dados_teste_reg.csv', names = ['user', \n",
    "                                                                       'movie', \n",
    "                                                                       'GAvg', \n",
    "                                                                       'sur1', \n",
    "                                                                       'sur2', \n",
    "                                                                       'sur3', \n",
    "                                                                       'sur4', \n",
    "                                                                       'sur5',\n",
    "                                                                       'smr1', \n",
    "                                                                       'smr2', \n",
    "                                                                       'smr3', \n",
    "                                                                       'smr4', \n",
    "                                                                       'smr5',\n",
    "                                                                       'UAvg', \n",
    "                                                                       'MAvg', \n",
    "                                                                       'rating'], \n",
    "                                 header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_teste_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CONSTRUINDO O MODELO DE MACHINE LEARNING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict para avaliaçao do modelo\n",
    "models_evaluation_train = {}\n",
    "models_evaluation_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao para calculo de erro do modelo\n",
    "def calcula_metricas(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean([(y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ] ))\n",
    "    mape = np.mean(np.abs( (y_true - y_pred)/ y_true)) * 100\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao para treino do modelo\n",
    "def exec_xgb(model, x_train, y_train, x_test, y_test, verbose = True):\n",
    "    \n",
    "    #dicts\n",
    "    train_results = {}\n",
    "    test_results = {}\n",
    "    \n",
    "    #treino \n",
    "    print(\"Treinando o modelo\")\n",
    "    model.fit(x_train, y_train, eval_metric = 'rmse')\n",
    "    print(\"Concluído\")\n",
    "    \n",
    "    #calculando o erro do modelo nos dados de treino\n",
    "    print('Calculando metricas em Treino')\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    rmse_train, mape_train = calcula_metricas(y_train.values, y_train_pred)\n",
    "    \n",
    "    #grava os resultados\n",
    "    train_results = {'rmse' : rmse_train, 'mape': mape_train, 'previsoes' : y_train_pred}\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nErro do modelo em treino')\n",
    "        print('-'*30)\n",
    "        print('RMSE: ', rmse_train)\n",
    "        print('MAPE: ' mape_train)\n",
    "        \n",
    "    #avaliando o modelo em dados de teste\n",
    "    print('\\nAvaliando o modelo em dados de teste')\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    rmse_test, mape_test = calcula_metricas(y_true = y_test.values, y_pred = y_test_pred)\n",
    "    \n",
    "    #grava resultados\n",
    "    test_results = {'rmse' : rmse_test, 'mape': mape_test, 'previsoes':y_test_pred}\n",
    "    if verbose:\n",
    "        print('\\nErro do modelo em teste')\n",
    "        print('-'*30)\n",
    "        print('RMSE: ', rmse_test)\n",
    "        print('MAPE: ' mape_test)\n",
    "    \n",
    "    return train_results, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "my_seed = 15\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TREINAMENTO DO MODELO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparando dados de treino\n",
    "x_treino = df_dados_treino_reg.drop(['user','movie','rating'], axis = 1)\n",
    "y_treino = df_dados_treino_reg['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dados de teste\n",
    "x_teste = df_dados_teste_reg.drop(['user', 'movie', 'rating'], axis = 1)\n",
    "y_teste = df_dados_teste_reg['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria o modelo xgboost regressor com 100 estimadores\n",
    "model_xgb = xgb.XGBRegressor(silent = False, random_state = 15, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinamento do modelo\n",
    "train_results, test_results = exec_xgb(model_xgb, x_treino, y_treino, x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazena os resultados da avaliação do modelo\n",
    "models_evaluation_train['modelo_xgb'] = train_results\n",
    "models_evaluation_test['modelo_xgb'] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variaveis mais importantes\n",
    "xgb.plot_importance(model_xgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de construir o modelo também identificamos as variáveis mais relevantes. Observe que não há surpresa. As avaliações de usuários são determinantes para recomendar os filmes avaliados para outros usuários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SALVANDO O RESULTADO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salva os resultados em disco\n",
    "pd.DataFrame(models_evaluation_test).to_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/resultado.csv')\n",
    "models = pd.read_csv('C:/Users/est.diegosv/OneDrive - Votorantim/Diego/ML/SistemaRecomendacao_Netflix/resultado.csv', index_col = 0)\n",
    "models.loc['rmse'].sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66b9b47f22d1b88f423820112b88cd64f7f51644863f32093beb15f57ac67cd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
